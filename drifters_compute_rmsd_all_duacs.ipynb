{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba67aa84",
   "metadata": {},
   "source": [
    "# RMSD drifters/DUACS – Verger-Miralles et al. (2025)\n",
    "\n",
    "**SWOT enhances small-scale eddy detection in the Mediterranean Sea**\n",
    "\n",
    "Author: *Elisabet Verger-Miralles*  \n",
    "Institution: IMEDEA (CSIC-UIB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085e3c3",
   "metadata": {},
   "source": [
    "Compute RMSD SVPB Drifters vels. module vs DUACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6ac77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.interpolate import griddata\n",
    "from datetime import datetime\n",
    "from functions import *\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (módulo): 0.1076 m/s\n",
      "RMSE dirección: 30.63 grados\n"
     ]
    }
   ],
   "source": [
    "# 1. DRIFTERS\n",
    "filedir = '../../grl_codes_to_publish_def_swotv2.0.1/data/drifters_filtered/SVPB/'\n",
    "dd1 = '2023-04-23T00:00:00.000000000'\n",
    "dd2 = '2023-04-29T00:00:00.000000000'\n",
    "drifter_ids = ['035', '039', '040', '041', '042']\n",
    "ds_drifters = []\n",
    "\n",
    "for num in drifter_ids:\n",
    "    url = filedir + f\"drifter-svpb{num}_inertial_osc_filt_subset.nc\"\n",
    "    ds = xr.open_dataset(url).sel(time=slice(dd1, dd2))\n",
    "    ds_drifters.append(ds)\n",
    "\n",
    "# 2. DUACS\n",
    "dir_DUACS = '../../grl_codes_to_publish_def_swotv2.0.1/data/DUACS/'\n",
    "files_d = np.sort(glob.glob(dir_DUACS + 'dt*.nc'))[0:8]\n",
    "lon_min, lon_max, lat_min, lat_max = 1.1, 1.9, 39.6, 40.1\n",
    "\n",
    "df_DUACS = None\n",
    "for file in files_d:\n",
    "    ds_DUACS = xr.open_dataset(file)\n",
    "    df_DUACS = process_and_concat_duacs(ds_DUACS, lon_min, lon_max, lat_min, lat_max, df_DUACS)\n",
    "\n",
    "df_DUACS = df_DUACS.dropna().reset_index(drop=True)\n",
    "df_DUACS['mean_time'] = df_DUACS.groupby(df_DUACS['time'].dt.date)['time'].transform('mean')\n",
    "\n",
    "group_transect_ugos = df_DUACS.groupby('mean_time')['ugos'].apply(list).reset_index()\n",
    "group_transect_vgos = df_DUACS.groupby('mean_time')['vgos'].apply(list).reset_index()\n",
    "group_transect_lon = df_DUACS.groupby('mean_time')['longitude'].apply(list).reset_index()\n",
    "group_transect_lat = df_DUACS.groupby('mean_time')['latitude'].apply(list).reset_index()\n",
    "\n",
    "# Mean per transect\n",
    "mean_transect_ugos = []\n",
    "mean_transect_vgos = []\n",
    "for i in range(len(group_transect_ugos)):\n",
    "    int_u = griddata((np.array(group_transect_lon['longitude'][i]),\n",
    "                      np.array(group_transect_lat['latitude'][i])),\n",
    "                     np.array(group_transect_ugos['ugos'][i]),\n",
    "                     (np.array(ds_drifters[0].LON), np.array(ds_drifters[0].LAT)), method='cubic')\n",
    "    int_v = griddata((np.array(group_transect_lon['longitude'][i]),\n",
    "                      np.array(group_transect_lat['latitude'][i])),\n",
    "                     np.array(group_transect_vgos['vgos'][i]),\n",
    "                     (np.array(ds_drifters[0].LON), np.array(ds_drifters[0].LAT)), method='cubic')\n",
    "    mean_transect_ugos.append(np.nanmean(int_u))\n",
    "    mean_transect_vgos.append(np.nanmean(int_v))\n",
    "\n",
    "unique_mean_times = df_DUACS['mean_time'].unique()\n",
    "df_DUACS['ugos_mean_transect'] = df_DUACS['mean_time'].map({t: mean_transect_ugos[i] for i, t in enumerate(unique_mean_times)})\n",
    "df_DUACS['vgos_mean_transect'] = df_DUACS['mean_time'].map({t: mean_transect_vgos[i] for i, t in enumerate(unique_mean_times)})\n",
    "\n",
    "# 3. SPATIOTEMPORAL INTERP. FOR ALL THE DRIFTERS\n",
    "u_svp_all, v_svp_all, u_duacs_all, v_duacs_all = [], [], [], []\n",
    "\n",
    "for ds in ds_drifters:\n",
    "    Lon, Lat = ds.LON.values, ds.LAT.values\n",
    "    u_svp, v_svp = ds.U.values, ds.V.values\n",
    "    t = np.array(ds.time)\n",
    "\n",
    "    u_duacs_int, v_duacs_int = [], []\n",
    "\n",
    "    for i in range(len(Lon)):\n",
    "        time_drifter = np.datetime64(t[i])\n",
    "        lon_drifter, lat_drifter = Lon[i], Lat[i]\n",
    "\n",
    "        df_DUACS['time_diff'] = abs(df_DUACS['mean_time'] - time_drifter)\n",
    "        sorted_diffs = df_DUACS['time_diff'].drop_duplicates().sort_values()\n",
    "        if len(sorted_diffs) < 2: continue\n",
    "        min1, min2 = sorted_diffs.iloc[0], sorted_diffs.iloc[1]\n",
    "\n",
    "        for min_diff in [min1, min2]:\n",
    "            subset = df_DUACS[df_DUACS['time_diff'] == min_diff]\n",
    "            ugos_an = subset['ugos'].values - np.nanmean(subset['ugos_mean_transect'].values)\n",
    "            vgos_an = subset['vgos'].values - np.nanmean(subset['vgos_mean_transect'].values)\n",
    "            lon_sw, lat_sw = subset['longitude'].values, subset['latitude'].values\n",
    "\n",
    "            u_interp = griddata((lon_sw, lat_sw), ugos_an, (lon_drifter, lat_drifter), method='cubic')\n",
    "            v_interp = griddata((lon_sw, lat_sw), vgos_an, (lon_drifter, lat_drifter), method='cubic')\n",
    "\n",
    "            if min_diff == min1:\n",
    "                u_interp1, v_interp1 = u_interp, v_interp\n",
    "            else:\n",
    "                u_interp2, v_interp2 = u_interp, v_interp\n",
    "\n",
    "        denom = min1 + min2\n",
    "        u_int_def = (u_interp1 * min2 + u_interp2 * min1) / denom\n",
    "        v_int_def = (v_interp1 * min2 + v_interp2 * min1) / denom\n",
    "\n",
    "        u_duacs_int.append(u_int_def)\n",
    "        v_duacs_int.append(v_int_def)\n",
    "\n",
    "    u_svp_all.extend(u_svp)\n",
    "    v_svp_all.extend(v_svp)\n",
    "    u_duacs_all.extend(u_duacs_int)\n",
    "    v_duacs_all.extend(v_duacs_int)\n",
    "\n",
    "u_svp_all = np.array(u_svp_all)\n",
    "v_svp_all = np.array(v_svp_all)\n",
    "u_duacs_all = np.array(u_duacs_all)\n",
    "v_duacs_all = np.array(v_duacs_all)\n",
    "\n",
    "# Module\n",
    "abs_vel_svp = np.sqrt(u_svp_all**2 + v_svp_all**2)\n",
    "abs_vel_duacs = np.sqrt(u_duacs_all**2 + v_duacs_all**2)\n",
    "\n",
    "rmsd = np.sqrt(np.nanmean((abs_vel_svp - abs_vel_duacs) ** 2))\n",
    "print(f'RMSE (módulo): {rmsd:.4f} m/s')\n",
    "\n",
    "# # Dirección\n",
    "# dir_vel_svp = np.degrees(np.arctan2(u_svp_all, v_svp_all))\n",
    "# dir_vel_duacs = np.degrees(np.arctan2(u_duacs_all, v_duacs_all))\n",
    "\n",
    "# def ang_err_180(angles):\n",
    "#     angles = np.where(angles < -180., 360 + angles, angles)\n",
    "#     angles = np.where(angles > 180., angles - 360, angles)\n",
    "#     return angles\n",
    "\n",
    "# angle_diff = ang_err_180(dir_vel_svp - dir_vel_duacs)\n",
    "# rmse_dir = np.sqrt(np.nanmean(angle_diff ** 2))\n",
    "# print(f'RMSE dirección: {rmse_dir:.2f} grados')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e6210",
   "metadata": {},
   "source": [
    "## BOOTSTRAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88f5bd",
   "metadata": {},
   "source": [
    "MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85a0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSD: 0.1076\n",
      "95% Confidence Interval: ConfidenceInterval(low=np.float64(0.10443535539969981), high=np.float64(0.11096026330652639))\n"
     ]
    }
   ],
   "source": [
    "def rmsd(drifter, swot, axis=0):\n",
    "    \"\"\"Compute Root Mean Square Deviation (RMSD).\"\"\"\n",
    "    diff = drifter - swot\n",
    "    return np.sqrt(np.nanmean(diff**2, axis=axis))\n",
    "\n",
    "# Combine data into a tuple without reshaping\n",
    "data = (abs_vel_svp, abs_vel_duacs)\n",
    "\n",
    "# Perform bootstrap resampling\n",
    "res = bootstrap(\n",
    "    data, \n",
    "    statistic=rmsd, \n",
    "    n_resamples=1000, \n",
    "    confidence_level=0.95, \n",
    "    method='BCa',  # Bias-Corrected and Accelerated bootstrap method\n",
    "    paired=True,  # Since we compare paired velocity values\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"RMSD: {rmsd(abs_vel_svp, abs_vel_duacs):.4f}\")\n",
    "# print(f\"RMSD: {rmsd(np.array(subsampling), np.array(subsampling_duacs)):.4f}\")\n",
    "\n",
    "print(f\"95% Confidence Interval: {res.confidence_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13072f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.10443535539969981), np.float64(0.11096026330652639))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low confidence interval\n",
    "low_ci = res.confidence_interval[0]\n",
    "high_ci = res.confidence_interval[1]\n",
    "low_ci, high_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c26282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0031646446003001927), np.float64(0.00336026330652639))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1076 - low_ci, high_ci - 0.1076 # longitude of the error bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd3272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3262453953413291)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((0.1076 - low_ci)*100) + ((high_ci - 0.1076)*100))/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_elisabet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
